# Druid集群部署
1、目前准备三台服务器分别为58.2.219.231，58.2.219.232，58.2.219.233。

<https://druid.apache.org/docs/latest/tutorials/cluster.html>

其中一台233为Master服务器用于运行 Coordinator and Overlord 服务。232为Data servers运行Historical 和 MiddleManager 服务。231服务器为query server用于运行Broker 和 Router 服务。
本次设置基于原druid服务器配置，metdata不迁移到mysql，data存储也不用hdfs。 
环境需求：jdk 1.8及以上。
三台服务器分别下载并解压到相应文件夹下。apache-druid-0.16.0-incubating-bin.tar.gz解压之后讲看到如下文件夹
  DISCLAIMER，LICENSE和NOTICE文件
  bin/*-与单机快速入门相关的脚本
  conf/druid/cluster/* -集群设置的模板配置
  extensions/* -核心德鲁伊扩展
  hadoop-dependencies/* -Druid Hadoop依赖项
  lib/* -核心Druid的库和依赖项
  quickstart/*-与单机快速入门相关的文件
  
2、配置Zookeeper连接 
在conf/druid/cluster/_common/common.runtime.properties文件中将druid.zk.service.host为 包含用逗号分隔的host：port对列表的连接字符串。如下：

druid.zk.service.host=58.2.219.233:2181,58.2.219.232:2181,58.2.219.231:2181

3、启动服务器
如果在主服务器上运行ZK，则可以使用以下命令与ZK一起启动主服务器进程

bin/start-cluster-master-with-zk-server

4、启动数据服务器

bin/start-cluster-data-server

5、启动查询服务器

bin/start-cluster-query-server


# Mysql作为metdata的配置方法。
1、将master服务器中的/usr/local/druid/apache-druid-0.16.0-incubating/conf/druid/cluster/_common/common.runtime.properties配置文件中的
  druid.extensions.loadList=["druid-hdfs-storage", "druid-kafka-indexing-service", "druid-datasketches","mysql-metadata-storage"]
  添加"mysql-metadata-storage"
  将# Metadata storage 中# For Derby server 注释掉，将mysql 部分打开（提前在MySQL中建好数据库）
  # For MySQL (make sure to include the MySQL JDBC driver on the classpath):
  druid.metadata.storage.type=mysql
  druid.metadata.storage.connector.connectURI=jdbc:mysql://58.2.221.232:3306/druid
  druid.metadata.storage.connector.user=druid
  druid.metadata.storage.connector.password=druid

2、下载mysql-connector-java-5.1.38.jar包到/usr/local/druid/apache-druid-0.16.0-incubating/extensions/mysql-metadata-storage
文件夹下。

3、启动master服务器即可。




